name: GCP integration test push

on:
 workflow_dispatch:
 push:
    branches:
      - main
      - web-sync

jobs:
 run-databricks-notebook:
   runs-on: ubuntu-latest
   steps:
     - name: Checkout repo
       uses: actions/checkout@v2
     - name: Run a databricks notebook
       uses: databricks/run-notebook@v0
       with:
         local-notebook-path: RUNME.py
         git-commit: ${{ github.sha }}
         databricks-host: https://416411475796958.8.gcp.databricks.com
         databricks-token: ${{ secrets.DEPLOYMENT_TARGET_TOKEN_GCP }}
         new-cluster-json: >
           {
              "num_workers": 0,
              "spark_version": "10.4.x-scala2.12",
              "node_type_id": "n1-highmem-4",
              "gcp_attributes": {
                "availability": "ON_DEMAND_GCP"
              },
              "spark_conf": {
                  "spark.master": "local[*, 4]",
                  "spark.databricks.cluster.profile": "singleNode"
              },
              "custom_tags": {
                  "ResourceClass": "SingleNode"
              }
            }
         notebook-params-json: >
           {
            "run_job": "True"
           }
         access-control-list-json: >
           [
             {
               "group_name": "users",
               "permission_level": "CAN_VIEW"
             }
           ]